{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Evaluation",
   "id": "72b581680efe610d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Qwen-2.5-14B-Instruct-GPTQ-Int4",
   "id": "a8305a1161716fd1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-30T07:09:09.893650Z",
     "start_time": "2025-04-30T07:09:08.430136Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "def read_jsonl(file_name:str):\n",
    "    data = []\n",
    "    with open(file_name, 'r') as f:\n",
    "        for line in f:\n",
    "            data.append(json.loads(line))\n",
    "    return data\n",
    "\n",
    "def jsonl_to_df(file_name:str):\n",
    "    results = read_jsonl(file_name)\n",
    "    df = pd.DataFrame(results)\n",
    "    df['buffer'] = None # the buffer is to prevent pycharm causing a rendering error\n",
    "    return df\n",
    "\n",
    "def count_number_of_reasoning_hits(df:pd.DataFrame):\n",
    "    count = df['results'].str.contains('{Yes}').sum()\n",
    "    return count"
   ],
   "id": "dc143aa405bc3ef2",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-30T07:09:10.461276Z",
     "start_time": "2025-04-30T07:09:10.373227Z"
    }
   },
   "cell_type": "code",
   "source": [
    "creak_14b_df = jsonl_to_df('results/Qwen2.5-14B-Instruct-GPTQ-Int4/ToG_creak.jsonl')\n",
    "cwq_14b_df = jsonl_to_df('results/Qwen2.5-14B-Instruct-GPTQ-Int4/ToG_cwq.jsonl')\n",
    "qald_14b_df = jsonl_to_df('results/Qwen2.5-14B-Instruct-GPTQ-Int4/ToG_qald.jsonl')\n",
    "trex_14b_df = jsonl_to_df('results/Qwen2.5-14B-Instruct-GPTQ-Int4/ToG_trex.jsonl')\n",
    "webqsp_14b_df = jsonl_to_df('results/Qwen2.5-14B-Instruct-GPTQ-Int4/ToG_webqsp.jsonl')\n",
    "webquestions_14b_df = jsonl_to_df('results/Qwen2.5-14B-Instruct-GPTQ-Int4/ToG_webquestions.jsonl')\n",
    "zeroshotre_14b_df = jsonl_to_df('results/Qwen2.5-14B-Instruct-GPTQ-Int4/ToG_zeroshotre.jsonl')\n",
    "df_14b = [creak_14b_df, cwq_14b_df, qald_14b_df, trex_14b_df, webqsp_14b_df, webquestions_14b_df, zeroshotre_14b_df]\n",
    "\n",
    "creak_7b_df = jsonl_to_df('results/Qwen2.5-7B-Instruct/ToG_creak.jsonl')\n",
    "cwq_7b_df = jsonl_to_df('results/Qwen2.5-7B-Instruct/ToG_cwq.jsonl')\n",
    "qald_7b_df = jsonl_to_df('results/Qwen2.5-7B-Instruct/ToG_qald.jsonl')\n",
    "trex_7b_df = jsonl_to_df('results/Qwen2.5-7B-Instruct/ToG_trex.jsonl')\n",
    "webqsp_7b_df = jsonl_to_df('results/Qwen2.5-7B-Instruct/ToG_webqsp.jsonl')\n",
    "webquestions_7b_df = jsonl_to_df('results/Qwen2.5-7B-Instruct/ToG_webquestions.jsonl')\n",
    "zeroshotre_7b_df = jsonl_to_df('results/Qwen2.5-7B-Instruct/ToG_zeroshotre.jsonl')\n",
    "df_7b = [creak_7b_df, cwq_7b_df, qald_7b_df, trex_7b_df, webqsp_7b_df, webquestions_7b_df, zeroshotre_7b_df]"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Hits@1 Evaluation",
   "id": "a2cbcd8cb4dec2f6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-30T07:09:10.652725Z",
     "start_time": "2025-04-30T07:09:10.585157Z"
    }
   },
   "cell_type": "code",
   "source": [
    "!cd\n",
    "import os\n",
    "os.chdir('eval')\n",
    "!cd"
   ],
   "id": "14e84c7b3f3e8fe",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Codes\\Experiments\\ToG\n",
      "C:\\Codes\\Experiments\\ToG\\eval\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Qwen-2.5-14B-Instruct-GPTQ-Int4",
   "id": "521c9155c9309ff1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-30T07:09:16.992208Z",
     "start_time": "2025-04-30T07:09:10.755259Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import time\n",
    "print(\"Evaluation of Creak (100 samples) with Hits@1:\")\n",
    "%run eval.py --dataset creak --output_file ..\\results\\Qwen2.5-14B-Instruct-GPTQ-Int4\\ToG_creak.jsonl --constraints_refuse True\n",
    "time.sleep(1)\n",
    "\n",
    "print(\"\\nEvaluation of CWQ (100 samples) with Hits@1:\")\n",
    "%run eval.py --dataset cwq --output_file ..\\results\\Qwen2.5-14B-Instruct-GPTQ-Int4\\ToG_cwq.jsonl --constraints_refuse True\n",
    "time.sleep(1)\n",
    "\n",
    "print(\"\\nEvaluation of QALD (100 samples) with Hits@1:\")\n",
    "%run eval.py --dataset qald --output_file ..\\results\\Qwen2.5-14B-Instruct-GPTQ-Int4\\ToG_qald.jsonl --constraints_refuse True\n",
    "time.sleep(1)\n",
    "\n",
    "print(\"\\nEvaluation of TREX (100 samples) with Hits@1:\")\n",
    "%run eval.py --dataset trex --output_file ..\\results\\Qwen2.5-14B-Instruct-GPTQ-Int4\\ToG_trex.jsonl --constraints_refuse True\n",
    "time.sleep(1)\n",
    "\n",
    "print(\"\\nEvaluation of WebQSP (100 samples) with Hits@1:\")\n",
    "%run eval.py --dataset webqsp --output_file ..\\results\\Qwen2.5-14B-Instruct-GPTQ-Int4\\ToG_webqsp.jsonl --constraints_refuse True\n",
    "time.sleep(1)\n",
    "\n",
    "print(\"\\nEvaluation of WebQuestions (100 samples) with Hits@1:\")\n",
    "%run eval.py --dataset webquestions --output_file ..\\results\\Qwen2.5-14B-Instruct-GPTQ-Int4\\ToG_webquestions.jsonl --constraints_refuse True\n",
    "time.sleep(1)\n",
    "\n",
    "print(\"\\nEvaluation of ZeroShotRE (100 samples) with Hits@1:\")\n",
    "%run eval.py --dataset zeroshotre --output_file ..\\results\\Qwen2.5-14B-Instruct-GPTQ-Int4\\ToG_zeroshotre.jsonl --constraints_refuse True"
   ],
   "id": "a8b80ef1c37999d9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation of Creak (100 samples) with Hits@1:\n",
      "Exact Match: 0.64\n",
      "right: 64, error: 36\n",
      "\n",
      "Evaluation of CWQ (100 samples) with Hits@1:\n",
      "Exact Match: 0.41\n",
      "right: 41, error: 58\n",
      "\n",
      "Evaluation of QALD (100 samples) with Hits@1:\n",
      "Exact Match: 0.5\n",
      "right: 50, error: 50\n",
      "\n",
      "Evaluation of TREX (100 samples) with Hits@1:\n",
      "Exact Match: 0.65\n",
      "right: 65, error: 35\n",
      "\n",
      "Evaluation of WebQSP (100 samples) with Hits@1:\n",
      "Exact Match: 0.65\n",
      "right: 65, error: 35\n",
      "\n",
      "Evaluation of WebQuestions (100 samples) with Hits@1:\n",
      "Exact Match: 0.46\n",
      "right: 46, error: 54\n",
      "\n",
      "Evaluation of ZeroShotRE (100 samples) with Hits@1:\n",
      "Exact Match: 0.7\n",
      "right: 70, error: 30\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Qwen-2.5-7B-Instruct",
   "id": "c857e3f6be3d4abe"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-30T07:09:23.286234Z",
     "start_time": "2025-04-30T07:09:17.099772Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"Evaluation of Creak (100 samples) with Hits@1:\")\n",
    "%run eval.py --dataset creak --output_file ..\\results\\Qwen2.5-7B-Instruct\\ToG_creak.jsonl --constraints_refuse True\n",
    "time.sleep(1)\n",
    "print(\"\\nEvaluation of CWQ (100 samples) with Hits@1:\")\n",
    "%run eval.py --dataset cwq --output_file ..\\results\\Qwen2.5-7B-Instruct\\ToG_cwq.jsonl --constraints_refuse True\n",
    "time.sleep(1)\n",
    "print(\"\\nEvaluation of QALD (100 samples) with Hits@1:\")\n",
    "%run eval.py --dataset qald --output_file ..\\results\\Qwen2.5-7B-Instruct\\ToG_qald.jsonl --constraints_refuse True\n",
    "time.sleep(1)\n",
    "print(\"\\nEvaluation of TREX (100 samples) with Hits@1:\")\n",
    "%run eval.py --dataset trex --output_file ..\\results\\Qwen2.5-7B-Instruct\\ToG_trex.jsonl --constraints_refuse True\n",
    "time.sleep(1)\n",
    "print(\"\\nEvaluation of WebQSP (100 samples) with Hits@1:\")\n",
    "%run eval.py --dataset webqsp --output_file ..\\results\\Qwen2.5-7B-Instruct\\ToG_webqsp.jsonl --constraints_refuse True\n",
    "time.sleep(1)\n",
    "print(\"\\nEvaluation of WebQuestions (100 samples) with Hits@1:\")\n",
    "%run eval.py --dataset webquestions --output_file ..\\results\\Qwen2.5-7B-Instruct\\ToG_webquestions.jsonl --constraints_refuse True\n",
    "time.sleep(1)\n",
    "print(\"\\nEvaluation of ZeroShotRE (100 samples) with Hits@1:\")\n",
    "%run eval.py --dataset zeroshotre --output_file ..\\results\\Qwen2.5-7B-Instruct\\ToG_zeroshotre.jsonl --constraints_refuse True"
   ],
   "id": "7ec0b067971a28a6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation of Creak (100 samples) with Hits@1:\n",
      "Exact Match: 0.5\n",
      "right: 50, error: 47\n",
      "\n",
      "Evaluation of CWQ (100 samples) with Hits@1:\n",
      "Exact Match: 0.38\n",
      "right: 38, error: 62\n",
      "\n",
      "Evaluation of QALD (100 samples) with Hits@1:\n",
      "Exact Match: 0.44\n",
      "right: 44, error: 55\n",
      "\n",
      "Evaluation of TREX (100 samples) with Hits@1:\n",
      "Exact Match: 0.61\n",
      "right: 61, error: 39\n",
      "\n",
      "Evaluation of WebQSP (100 samples) with Hits@1:\n",
      "Exact Match: 0.48\n",
      "right: 48, error: 52\n",
      "\n",
      "Evaluation of WebQuestions (100 samples) with Hits@1:\n",
      "Exact Match: 0.44\n",
      "right: 44, error: 56\n",
      "\n",
      "Evaluation of ZeroShotRE (100 samples) with Hits@1:\n",
      "Exact Match: 0.37\n",
      "right: 37, error: 63\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-30T07:09:23.428041Z",
     "start_time": "2025-04-30T07:09:23.393169Z"
    }
   },
   "cell_type": "code",
   "source": [
    "os.chdir('..')\n",
    "!cd"
   ],
   "id": "284ddf48a7df20f9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Codes\\Experiments\\ToG\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Number of KG Reasoning Hits",
   "id": "6a100e90dbbd574c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-30T07:09:23.579030Z",
     "start_time": "2025-04-30T07:09:23.552884Z"
    }
   },
   "cell_type": "code",
   "source": [
    "creak_14b_reasoning_hits = count_number_of_reasoning_hits(creak_14b_df)\n",
    "creak_7b_reasoning_hits = count_number_of_reasoning_hits(creak_7b_df)\n",
    "cwq_14b_reasoning_hits = count_number_of_reasoning_hits(cwq_14b_df)\n",
    "cwq_7b_reasoning_hits = count_number_of_reasoning_hits(cwq_7b_df)\n",
    "qald_14b_reasoning_hits = count_number_of_reasoning_hits(qald_14b_df)\n",
    "qald_7b_reasoning_hits = count_number_of_reasoning_hits(qald_7b_df)\n",
    "trex_14b_reasoning_hits = count_number_of_reasoning_hits(trex_14b_df)\n",
    "trex_7b_reasoning_hits = count_number_of_reasoning_hits(trex_7b_df)\n",
    "webqsp_14b_reasoning_hits = count_number_of_reasoning_hits(webqsp_14b_df)\n",
    "webqsp_7b_reasoning_hits = count_number_of_reasoning_hits(webqsp_7b_df)\n",
    "webquestions_14b_reasoning_hits = count_number_of_reasoning_hits(webquestions_14b_df)\n",
    "webquestions_7b_reasoning_hits = count_number_of_reasoning_hits(webquestions_7b_df)\n",
    "zeroshotre_14b_reasoning_hits = count_number_of_reasoning_hits(zeroshotre_14b_df)\n",
    "zeroshotre_7b_reasoning_hits = count_number_of_reasoning_hits(zeroshotre_7b_df)\n",
    "kg_reasoning_hits_14b = [creak_14b_reasoning_hits, cwq_14b_reasoning_hits, qald_14b_reasoning_hits, trex_14b_reasoning_hits, webqsp_14b_reasoning_hits, webquestions_14b_reasoning_hits, zeroshotre_14b_reasoning_hits]\n",
    "kg_reasoning_hits_7b = [creak_7b_reasoning_hits, cwq_7b_reasoning_hits, qald_7b_reasoning_hits, trex_7b_reasoning_hits, webqsp_7b_reasoning_hits, webquestions_7b_reasoning_hits, zeroshotre_7b_reasoning_hits]\n",
    "\n",
    "dataset_names = ['Creak', 'CWQ', 'QALD', 'TREX', 'WebQSP', 'WebQuestions', 'ZeroShotRE']\n",
    "\n",
    "for i in range(len(dataset_names)):\n",
    "    print(f\"Number of KG Reasoning Hits for {dataset_names[i]}: {kg_reasoning_hits_14b[i]} (14B), {kg_reasoning_hits_7b[i]} (7B)\")"
   ],
   "id": "10f0772a1aad6237",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of KG Reasoning Hits for Creak: 14 (14B), 6 (7B)\n",
      "Number of KG Reasoning Hits for CWQ: 33 (14B), 19 (7B)\n",
      "Number of KG Reasoning Hits for QALD: 41 (14B), 17 (7B)\n",
      "Number of KG Reasoning Hits for TREX: 81 (14B), 56 (7B)\n",
      "Number of KG Reasoning Hits for WebQSP: 64 (14B), 25 (7B)\n",
      "Number of KG Reasoning Hits for WebQuestions: 55 (14B), 34 (7B)\n",
      "Number of KG Reasoning Hits for ZeroShotRE: 74 (14B), 35 (7B)\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Reasoning Hits to Hits@1 Ratio",
   "id": "5db8a7eee568c8f1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-30T07:09:23.688930Z",
     "start_time": "2025-04-30T07:09:23.677153Z"
    }
   },
   "cell_type": "code",
   "source": [
    "hits_at1_14b = [0.64, 0.41, 0.5, 0.65, 0.65, 0.46, 0.7]\n",
    "hits_at1_7b = [0.5, 0.38,0.44,0.61,0.48,0.44,0.37]\n",
    "\n",
    "idx = 0\n",
    "\n",
    "for a,b in zip(hits_at1_14b, kg_reasoning_hits_14b):\n",
    "    print(f\"Ratio of Reasoning Hits to Hits@1 {dataset_names[idx]} (14B): {(b/100)/a:.2f}\")\n",
    "    idx += 1\n",
    "idx  = 0\n",
    "\n",
    "print()\n",
    "for a,b in zip(hits_at1_7b, kg_reasoning_hits_7b):\n",
    "    print(f\"Ratio of Reasoning Hits to Hits@1 {dataset_names[idx]} (7B): {(b/100)/a:.2f}\")\n",
    "    idx += 1"
   ],
   "id": "ae0044367b21496c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratio of Reasoning Hits to Hits@1 Creak (14B): 0.22\n",
      "Ratio of Reasoning Hits to Hits@1 CWQ (14B): 0.80\n",
      "Ratio of Reasoning Hits to Hits@1 QALD (14B): 0.82\n",
      "Ratio of Reasoning Hits to Hits@1 TREX (14B): 1.25\n",
      "Ratio of Reasoning Hits to Hits@1 WebQSP (14B): 0.98\n",
      "Ratio of Reasoning Hits to Hits@1 WebQuestions (14B): 1.20\n",
      "Ratio of Reasoning Hits to Hits@1 ZeroShotRE (14B): 1.06\n",
      "\n",
      "Ratio of Reasoning Hits to Hits@1 Creak (7B): 0.12\n",
      "Ratio of Reasoning Hits to Hits@1 CWQ (7B): 0.50\n",
      "Ratio of Reasoning Hits to Hits@1 QALD (7B): 0.39\n",
      "Ratio of Reasoning Hits to Hits@1 TREX (7B): 0.92\n",
      "Ratio of Reasoning Hits to Hits@1 WebQSP (7B): 0.52\n",
      "Ratio of Reasoning Hits to Hits@1 WebQuestions (7B): 0.77\n",
      "Ratio of Reasoning Hits to Hits@1 ZeroShotRE (7B): 0.95\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Hits@1\n",
    "\n",
    "14B\n",
    "\n",
    "Creak: 0.64\n",
    "\n",
    "CWQ: 0.41\n",
    "\n",
    "QALD: 0.5\n",
    "\n",
    "TREX: 0.65\n",
    "\n",
    "WebQSP: 0.65\n",
    "\n",
    "WebQuestions: 0.46\n",
    "\n",
    "ZeroShotRE: 0.7\n",
    "\n",
    "7B\n",
    "\n",
    "Creak: 0.5\n",
    "\n",
    "CWQ: 0.38\n",
    "\n",
    "QALD: 0.44\n",
    "\n",
    "TREX: 0.61\n",
    "\n",
    "WebQSP: 0.48\n",
    "\n",
    "WebQuestions: 0.44\n",
    "\n",
    "ZeroShotRE: 0.37"
   ],
   "id": "68f6990217c211a8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-30T07:11:12.523370Z",
     "start_time": "2025-04-30T07:11:12.513286Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_average_runtime(df:pd.DataFrame):\n",
    "    return df['logs'].apply(lambda x: float(x['runtime'])).sum()/len(df)\n",
    "\n",
    "def get_average_llm_call_count(df:pd.DataFrame):\n",
    "    return df['logs'].apply(lambda x: int(x['llm_call_count'])).sum()/len(df)\n",
    "\n",
    "def get_average_kg_call_count(df:pd.DataFrame):\n",
    "    return df['logs'].apply(lambda x: int(x['wikidata_call_count'])).sum()/len(df)\n",
    "\n",
    "def get_average_depth(df:pd.DataFrame):\n",
    "    return df['logs'].apply(lambda x: int(x['depth'])).sum()/len(df)\n",
    "\n",
    "def get_runtimes(df:pd.DataFrame):\n",
    "    return df['logs'].apply(lambda x: float(x['runtime'])).sum()"
   ],
   "id": "1af20586fe4a6594",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-30T07:11:13.718504Z",
     "start_time": "2025-04-30T07:11:13.703139Z"
    }
   },
   "cell_type": "code",
   "source": [
    "total_runtimes_14b = [get_runtimes(df) for df in df_14b]\n",
    "total_runtimes_7b = [get_runtimes(df) for df in df_7b]\n",
    "print(\"Total runtimes for 14B:\")\n",
    "for i in range(len(dataset_names)):\n",
    "    print(f\"{dataset_names[i]}: {total_runtimes_14b[i]:.2f}\")\n",
    "print(\"Total runtimes for 7B:\")\n",
    "for i in range(len(dataset_names)):\n",
    "    print(f\"{dataset_names[i]}: {total_runtimes_7b[i]:.2f}\")"
   ],
   "id": "3a9deaba1c0fe43a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total runtimes for 14B:\n",
      "Creak: 19765.55\n",
      "CWQ: 21968.39\n",
      "QALD: 17385.28\n",
      "TREX: 7446.41\n",
      "WebQSP: 12798.28\n",
      "WebQuestions: 15486.09\n",
      "ZeroShotRE: 10797.09\n",
      "Total runtimes for 7B:\n",
      "Creak: 9644.89\n",
      "CWQ: 12685.58\n",
      "QALD: 12601.32\n",
      "TREX: 13623.93\n",
      "WebQSP: 6027.67\n",
      "WebQuestions: 8136.98\n",
      "ZeroShotRE: 11670.75\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-30T07:09:23.999172Z",
     "start_time": "2025-04-30T07:09:23.972968Z"
    }
   },
   "cell_type": "code",
   "source": [
    "runtimes_14b = [get_average_runtime(df) for df in df_14b]\n",
    "llm_call_counts_14b = [get_average_llm_call_count(df) for df in df_14b]\n",
    "kg_call_counts_14b = [get_average_kg_call_count(df) for df in df_14b]\n",
    "depths_14b = [get_average_depth(df) for df in df_14b]\n",
    "\n",
    "runtimes_7b = [get_average_runtime(df) for df in df_7b]\n",
    "llm_call_counts_7b = [get_average_llm_call_count(df) for df in df_7b]\n",
    "kg_call_counts_7b = [get_average_kg_call_count(df) for df in df_7b]\n",
    "depths_7b = [get_average_depth(df) for df in df_7b]"
   ],
   "id": "eafa6cd308986b99",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-30T07:09:24.110635Z",
     "start_time": "2025-04-30T07:09:24.101417Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for i in range(len(dataset_names)):\n",
    "    print(f\"Average Runtime for {dataset_names[i]}: {runtimes_14b[i]:.2f} (14B), {runtimes_7b[i]:.2f} (7B)\")\n",
    "print()\n",
    "\n",
    "for i in range(len(dataset_names)):\n",
    "    print(f\"Average LLM Call Count for {dataset_names[i]}: {llm_call_counts_14b[i]:.2f} (14B), {llm_call_counts_7b[i]:.2f} (7B)\")\n",
    "print()\n",
    "\n",
    "for i in range(len(dataset_names)):\n",
    "    print(f\"Average KG Call Count for {dataset_names[i]}: {kg_call_counts_14b[i]:.2f} (14B), {kg_call_counts_7b[i]:.2f} (7B)\")\n",
    "print()\n",
    "\n",
    "for i in range(len(dataset_names)):\n",
    "    print(f\"Average Depth for {dataset_names[i]}: {depths_14b[i]:.2f} (14B), {depths_7b[i]:.2f} (7B)\")"
   ],
   "id": "c79dd9076ef139b8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Runtime for Creak: 197.66 (14B), 96.45 (7B)\n",
      "Average Runtime for CWQ: 219.68 (14B), 126.86 (7B)\n",
      "Average Runtime for QALD: 173.85 (14B), 126.01 (7B)\n",
      "Average Runtime for TREX: 74.46 (14B), 136.24 (7B)\n",
      "Average Runtime for WebQSP: 127.98 (14B), 60.28 (7B)\n",
      "Average Runtime for WebQuestions: 154.86 (14B), 81.37 (7B)\n",
      "Average Runtime for ZeroShotRE: 107.97 (14B), 116.71 (7B)\n",
      "\n",
      "Average LLM Call Count for Creak: 14.95 (14B), 8.80 (7B)\n",
      "Average LLM Call Count for CWQ: 13.22 (14B), 8.78 (7B)\n",
      "Average LLM Call Count for QALD: 11.11 (14B), 9.74 (7B)\n",
      "Average LLM Call Count for TREX: 4.35 (14B), 7.67 (7B)\n",
      "Average LLM Call Count for WebQSP: 7.64 (14B), 4.50 (7B)\n",
      "Average LLM Call Count for WebQuestions: 9.44 (14B), 6.51 (7B)\n",
      "Average LLM Call Count for ZeroShotRE: 6.27 (14B), 9.30 (7B)\n",
      "\n",
      "Average KG Call Count for Creak: 70.04 (14B), 37.06 (7B)\n",
      "Average KG Call Count for CWQ: 64.80 (14B), 35.91 (7B)\n",
      "Average KG Call Count for QALD: 53.27 (14B), 42.81 (7B)\n",
      "Average KG Call Count for TREX: 19.86 (14B), 35.28 (7B)\n",
      "Average KG Call Count for WebQSP: 35.51 (14B), 16.47 (7B)\n",
      "Average KG Call Count for WebQuestions: 45.00 (14B), 26.77 (7B)\n",
      "Average KG Call Count for ZeroShotRE: 30.00 (14B), 42.30 (7B)\n",
      "\n",
      "Average Depth for Creak: 2.67 (14B), 1.57 (7B)\n",
      "Average Depth for CWQ: 2.37 (14B), 1.53 (7B)\n",
      "Average Depth for QALD: 2.05 (14B), 1.72 (7B)\n",
      "Average Depth for TREX: 1.30 (14B), 1.84 (7B)\n",
      "Average Depth for WebQSP: 1.69 (14B), 0.78 (7B)\n",
      "Average Depth for WebQuestions: 1.86 (14B), 1.18 (7B)\n",
      "Average Depth for ZeroShotRE: 1.53 (14B), 1.99 (7B)\n"
     ]
    }
   ],
   "execution_count": 11
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
